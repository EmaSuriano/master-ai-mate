{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02MIAR Actividad evaluada â€” ejercicio\n",
    "\n",
    "â—ï¸TODO: Agregar nombres\n",
    "\n",
    "Grupo 5 de Matematicas:\n",
    "\n",
    "- Julio Emanuel Suriano Bryk\n",
    "\n",
    "Para hacer:\n",
    "\n",
    "- Completar TODO\n",
    "- Cambiar comentarios al espaniol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup del proyecto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utils libs\n",
    "import copy\n",
    "import random\n",
    "from functools import reduce\n",
    "from timeit import timeit\n",
    "\n",
    "# graphical libs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# typehint libs\n",
    "from typing import Callable\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Avoid annoying warning for deprecations ...\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# make plots with visible on export\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers functions\n",
    "def get_square_matrix(n: int, n_range: tuple[int, int] = (-10, 10)) -> list[list]:\n",
    "    \"\"\"generate random matrix of n size\n",
    "\n",
    "    Args:\n",
    "        n (int): amount of rows/columns\n",
    "        n_range (tuple[int, int], optional): range of numbers for each item in the matrix. Defaults to (0, 100).\n",
    "\n",
    "    Returns:\n",
    "        list[list]: generated matrix\n",
    "    \"\"\"\n",
    "    return [[random.randint(*n_range) for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "\n",
    "def matrix_to_str(matrix: list[list]) -> str:\n",
    "    \"\"\"Return a string with the representation of the matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): matrix that you want to display\n",
    "\n",
    "    Returns:\n",
    "        str: representation of matrix\n",
    "    \"\"\"\n",
    "    digits = max(len(f\"{num:.2f}\") for row in matrix for num in row)\n",
    "    res = map(lambda row: \" \".join([f\"{n:{digits}.{2}f}\" for n in row]), matrix)\n",
    "    return \"\\n\".join(res)\n",
    "\n",
    "\n",
    "dimensions = [2, 3, 4]\n",
    "\n",
    "for n in dimensions:\n",
    "    matrix = get_square_matrix(n)\n",
    "    print(f\"Matrix {n}x{n}: \")\n",
    "    print(matrix_to_str(matrix))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 (2 puntos). Desarrollo de Laplace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deducir de la definiciÃ³n 4 el determinante en dimensiÃ³n 0, 1 y 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸TODO: Completar aca las definiciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir de la definiciÃ³n 4, expresar el determinante de una matriz cuadrada recursivamente en funciÃ³n de determinantes la matrices cuadradas de dimensiÃ³n inferior.\n",
    "\n",
    "IndicaciÃ³n: para cada $ð‘› âˆˆ N$, distribuir (por linealidad en las columnas) sobre la descomposiciÃ³n\n",
    "\n",
    "$$\n",
    "\\det\\begin{pmatrix} ðœ† & w \\\\ v & A \\end{pmatrix} = \\det\\begin{pmatrix} ðœ† * 1 + 0 & w \\\\ ðœ† * 0 + v & A \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "de una matriz cuadrada de dimensiÃ³n $ð‘› + 1$, siendo $ð‘› âˆˆ N$ y\n",
    "\n",
    "- ðœ† un coeficiente real,\n",
    "- ð‘£ un vector de dimensiÃ³n ð‘› (una columna de ð‘› coeficientes reales),\n",
    "- ðœ” un covector de la misma dimensiÃ³n (una fila de ð‘› coeficientes),\n",
    "- ð´ una matriz cuadrada de la misma dimensiÃ³n (con ð‘›2 coeficientes),\n",
    "\n",
    "luego proceder del mismo modo\n",
    "\n",
    "- con los demÃ¡s coeficientes de esa primera columna,\n",
    "- con cada columna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸TODO: completar esta seccion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar en Python la definiciÃ³n asÃ­ obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_determinant(matrix: list[list]) -> float:\n",
    "    \"\"\"get determinant of a matrix using Laplace recursive method\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): squared matrix to obtain the determinant from\n",
    "\n",
    "    Raises:\n",
    "        Exception: in case the matrix is not squared\n",
    "\n",
    "    Returns:\n",
    "        float: value of the determinant\n",
    "    \"\"\"\n",
    "    if len(matrix) != len(matrix[0]):\n",
    "        raise Exception(\"Matriz no es cuadrada...\")\n",
    "\n",
    "    if len(matrix) == 1:\n",
    "        return matrix[0][0]\n",
    "\n",
    "    if len(matrix) == 2:\n",
    "        a, b = matrix[0]\n",
    "        c, d = matrix[1]\n",
    "        return a * d - b * c\n",
    "\n",
    "    res = 0\n",
    "    for i, n in enumerate(matrix[0]):\n",
    "        sub_matrix = [[el for j, el in enumerate(row) if j != i] for row in matrix[1:]]\n",
    "        res += n * (-1) ** i * laplace_determinant(sub_matrix)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(3)\n",
    "\n",
    "print(\"Matriz:\")\n",
    "print(matrix_to_str(matrix))\n",
    "print(\"Determinante:\", laplace_determinant(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 (2 puntos). EliminaciÃ³n de Gaussâ€“Jordan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deducir de la definiciÃ³n 4 el efecto que tiene en el determinante de una matriz sumar a una de sus columnas una combinaciÃ³n lineal de las demÃ¡s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸ TODO: Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir de la definiciÃ³n 4, proponer una estrategia para triangularizar una matriz sin cambiar su determinante e implementar en Python una definiciÃ³n alternativa del determinante.\n",
    "\n",
    "IndicaciÃ³n: descomponer similarmente al ejercicio anterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸ TODO: Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar en Python la definiciÃ³n asÃ­ obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(initial_matrix: list[list]) -> tuple[list[list], float]:\n",
    "    \"\"\"perform the gaussian elimination method for a given matrix\n",
    "\n",
    "    Args:\n",
    "        initial_matrix (list[list]): matrix to apply gaussian elimination\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[list], float]: triangular matrix along with its determinant\n",
    "    \"\"\"\n",
    "    matrix = copy.deepcopy(initial_matrix)\n",
    "    n = len(matrix)\n",
    "\n",
    "    # keep track of row swaps to calculate final determinant\n",
    "    sign = 1\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        # find the proper row pivot to avoid zero division and rounded errors\n",
    "        max_row = max(range(i, n), key=lambda j: abs(matrix[j][i]))\n",
    "        if max_row != i:\n",
    "            matrix[i], matrix[max_row] = matrix[max_row], matrix[i]\n",
    "            sign *= -1\n",
    "\n",
    "        # apply rows operations in order to ensure triangularly of the matrix\n",
    "        for j in range(i + 1, n):\n",
    "            factor = matrix[j][i] / matrix[i][i]\n",
    "            for k in range(i, n):\n",
    "                matrix[j][k] -= matrix[i][k] * factor\n",
    "\n",
    "    # calculate determinant of a matrix using only the diagonal of it\n",
    "    diagonal_value = reduce(lambda acc, i: acc * matrix[i][i], range(n), 1)\n",
    "    determinant = diagonal_value * sign\n",
    "\n",
    "    return (matrix, determinant)\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(3)\n",
    "\n",
    "print(\"Matriz original:\")\n",
    "print(matrix_to_str(matrix))\n",
    "print(\"Determinante:\", laplace_determinant(matrix))\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "(triangular_matrix, triangular_determinant) = gaussian_elimination(matrix)\n",
    "print(\"Matriz triangular:\")\n",
    "print(matrix_to_str(triangular_matrix))\n",
    "print(\"Determinante:\", f\"{triangular_determinant:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 (2 puntos). ComparaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtener la complejidad computacional de cada una de estas dos implementaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complejidad computacional para el calculo del determinante:\n",
    "\n",
    "- Definicion con Laplace: $O(n!)$ por su propiedad recursiva\n",
    "- Definicion con Gauss: $O(n^3)$ son 3 `for` anidados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generar matrices aleatoriamente en dimensiÃ³n $ð‘› âˆˆ { 2, 3, Â· Â· Â· , 9, 10 }$ y comparar el tiempo de ejecuciÃ³n de cada una de estas dos implementaciones con la funciÃ³n `numpy.linalg.det` (la funciÃ³n determinante de la extensiÃ³n numÃ©rica de Python al Ã¡lgebra lineal).\n",
    "\n",
    "IndicaciÃ³n: se puede utilizar la funciÃ³n `numpy.random.rand` para generar los coeficientes aleatorios de sus matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "input_sizes = [np.random.rand(n, n).tolist() for n in range(2, 11)]\n",
    "\n",
    "for n in input_sizes:\n",
    "    recur_time = timeit(lambda: laplace_determinant(n), number=1)\n",
    "    gauss_time = timeit(lambda: gaussian_elimination(n), number=1)\n",
    "    numpy_time = timeit(lambda: np.linalg.det(n), number=1)\n",
    "\n",
    "    data.extend(\n",
    "        [\n",
    "            [\"Recursive\", len(n), recur_time],\n",
    "            [\"Gauss\", len(n), gauss_time],\n",
    "            [\"Numpy\", len(n), numpy_time],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Method\", \"n\", \"Time\"])\n",
    "\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=\"n\",\n",
    "    y=\"Time\",\n",
    "    color=\"Method\",\n",
    "    markers=True,\n",
    "    title=\"Time to calculate matrix determinant\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 (4 puntos).\n",
    "\n",
    "Con el propÃ³sito de aproximar un mÃ­nimo local de una funciÃ³n real de varias variables reales, el mÃ©todo de descenso de gradiente consiste en iterar una marcha (positivamente) proporcional al (opuesto del) gradiente desde un valor inicial, con la intuiciÃ³n de â€˜seguir el aguaâ€™ hasta dar con el valle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to draw functions\n",
    "\n",
    "\n",
    "def draw_function_2d_with_gradient(\n",
    "    f: Callable,\n",
    "    graph_range: tuple[float, float],\n",
    "    descent_history: NDArray,\n",
    "    title: str,\n",
    "):\n",
    "    \"\"\"Create plot using plotly to represent a gradient descent result of function\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "        title (str): title for the graph\n",
    "    \"\"\"\n",
    "    # Vectorize function in order to be possible to support numpy array operations\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    x = np.linspace(*graph_range, 100)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=f_vector(x), mode=\"lines\", name=\"Function\"))\n",
    "\n",
    "    descent_df = pd.DataFrame(\n",
    "        [(*p, f_vector(*p)) for p in descent_history], columns=[\"x\", \"y\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=descent_df[\"x\"],\n",
    "                y=descent_df[\"y\"],\n",
    "                mode=\"markers\",\n",
    "                name=\"Gradient\",\n",
    "            )\n",
    "        )\n",
    "    except OverflowError:\n",
    "        print(\"Cannot draw gradient history due to Overflow Error\")\n",
    "\n",
    "    fig.update_layout(title=title)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def draw_function_3d_with_gradient(\n",
    "    f: Callable,\n",
    "    graph_range: tuple[float, float],\n",
    "    descent_history: NDArray,\n",
    "    title: str,\n",
    "):\n",
    "    \"\"\"Create plot using plotly to represent a gradient descent result of function\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "        title (str): title for the graph\n",
    "    \"\"\"\n",
    "    # Vectorize function in order to be possible to support numpy array operations\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    # Create a grid of x and y values\n",
    "    x, y = np.meshgrid(np.linspace(*graph_range, 10), np.linspace(*graph_range, 10))\n",
    "    z = f_vector(x, y)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = go.Figure(data=[go.Surface(z=z, x=x, y=y, opacity=0.7)])\n",
    "\n",
    "    # convert history to pandas df\n",
    "    descent_df = pd.DataFrame(\n",
    "        [(*p, f_vector(*p)) for p in descent_history], columns=[\"x\", \"y\", \"z\"]\n",
    "    )\n",
    "\n",
    "    # mark start and end point of the gradient history\n",
    "    points_df = pd.concat([descent_df.iloc[[0]], descent_df.iloc[[-1]]])\n",
    "    fig.add_traces(\n",
    "        go.Scatter3d(\n",
    "            x=points_df[\"x\"],\n",
    "            y=points_df[\"y\"],\n",
    "            z=points_df[\"z\"],\n",
    "            mode=\"markers+text\",\n",
    "            text=[\"Start\", \"End\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # add gradient line\n",
    "    fig.add_traces(\n",
    "        px.line_3d(\n",
    "            descent_df, x=\"x\", y=\"y\", z=\"z\", color_discrete_sequence=[\"white\"]\n",
    "        ).data\n",
    "    )\n",
    "\n",
    "    fig.update_layout(title=title)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementar en Python un algoritmo de descenso de gradiente (con un mÃ¡ximo de $m = 10**5$ iteraciones) a partir de los siguientes argumentos tomados en ese orden:\n",
    "\n",
    "- la funciÃ³n $f$ cuyo mÃ­nimo local se propone aproximar,\n",
    "- el valor inicial $x$ desde el que empieza la marcha,\n",
    "- la razÃ³n geomÃ©trica o coeficiente de proporcionalidad $y$,\n",
    "- el parÃ¡metro de tolerancia $z$ para finalizar cuando el gradiente de la funciÃ³n $f$ caiga dentro de esa tolerancia.\n",
    "\n",
    "IndicaciÃ³n: empezar por implementar el gradiente `grad(f)` de la funciÃ³n $f$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size\n",
    "grad_step_size = 0.0001\n",
    "\n",
    "\n",
    "def get_gradient_using_step(f: Callable, x: NDArray) -> NDArray:\n",
    "    \"\"\"calculate gradient for the function at a given point by using the method of\n",
    "\n",
    "    Args:\n",
    "        f (Callable): _description_\n",
    "        x (NDArray): _description_\n",
    "\n",
    "    Returns:\n",
    "        NDArray: _description_\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        point_with_step = x.copy()\n",
    "        point_with_step[i] = point_with_step[i] + grad_step_size\n",
    "        grad[i] = (f(*point_with_step) - f(*x)) / grad_step_size\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def grad(\n",
    "    f: Callable,\n",
    "    x: NDArray,\n",
    "    y=0.01,\n",
    "    m=10**5,\n",
    "    z=1e-6,\n",
    ") -> list[NDArray]:\n",
    "    \"\"\"get minimum point of a function using method of gradient descent with step\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to find the minimum point\n",
    "        x (NDArray): start point to start looking for the minimum point\n",
    "        y (float, optional): learning rate to move the point on each iteration. Defaults to 0.01.\n",
    "        m (int, optional): numbers of max iterations to run. Defaults to 10**5.\n",
    "        z (float, optional): tolerance value to finish the algorithm in case we found point of convergence. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        list[NDArray]: history of the points inside the algorithm of gradient descent\n",
    "    \"\"\"\n",
    "    point = x\n",
    "    history = np.array([point])\n",
    "\n",
    "    for _ in range(m):\n",
    "        # get gradient from the derivate function\n",
    "        grad = get_gradient_using_step(f, point)\n",
    "\n",
    "        # Check for point convergence\n",
    "        if np.linalg.norm(grad) * 2 < z:\n",
    "            break\n",
    "\n",
    "        # get new point for the next iteration\n",
    "        point -= grad * y\n",
    "\n",
    "        # save it in history\n",
    "        history = np.concatenate((history, [point]), axis=0)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcular formalmente ${ ð‘¡ âˆˆ R. ð‘“ â€²(ð‘¡) = 0 }$ para $f(t) = 3t^4 + 4t^3 âˆ’ 12t^2 + 7$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  f'(t) = 12 t^3 + 12 t^2 - 24 t \\\\\n",
    "  f'(t) = 12 t (t^2 + t - 2)\n",
    "$$\n",
    "\n",
    "Para que $f'(t) = 0$, entonces los puntos criticos son:\n",
    "\n",
    "$$\n",
    "  t = -2\\\\\n",
    "  t = 0 \\\\\n",
    "  t = 1 \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Con una tolerancia $z = 10**-12$ y un valor inicial de $x = 3$ aplicar su algoritmo con razÃ³n $y = 10**-1, 10**-2, 10**-3$ luego hacer lo mismo con $x = 0$. Interpretar el resultado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—TODO: agregar interpretaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: float) -> float:\n",
    "    return 3 * (x**4) + 4 * (x**3) - 12 * x**2 + 7\n",
    "\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.001)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    (-3, 3),\n",
    "    descent_history,\n",
    "    title=f\"x = 3 y=10^-3 encontro punto minimo (local) en {descent_history[-1]}\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.01)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    (-3, 3),\n",
    "    descent_history,\n",
    "    title=f\"x = 3 y=10^-2 encontro punto minimo (global) en {descent_history[-1]}\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.1)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    (-3, 3),\n",
    "    descent_history,\n",
    "    title=\"x = 3 y=10^-1 no encontro un punto minimo valido por el alto valor de learning rate\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[0], y=0.001)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    (-3, 3),\n",
    "    descent_history,\n",
    "    title=\"x=0 y=10^-1 Es un punto de silla de f, por lo que no convergio a ningun punto minimo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repetir estos dos Ãºltimos apartados con $f: (s,t) â†’ s^2 + 3st + t^3 + 1$ y los valores iniciales $x = [-1,1], [0,0]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivadas parciales:\n",
    "\n",
    "$$\n",
    "  f'(s,t)_s = 2s + 3t \\\\\n",
    "  f'(s,t)_t = 3s + 3t ^2 \\\\\n",
    "$$\n",
    "\n",
    "Para que $f'(t) = 0$, entonces los puntos criticos son:\n",
    "\n",
    "$$\n",
    "  (s_1=0,t_1=0) \\\\\n",
    "  (s_2= 9/4, t_2= 3/2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—TODO: agregar interpretaciones\n",
    "\n",
    "Ema: solucionar grafico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(s: float, t: float) -> float:\n",
    "    return s**2 + 3 * s * t + t**3 + 1\n",
    "\n",
    "\n",
    "descent_history = grad(f, x=[-0, 1], y=0.001)\n",
    "title = f\"x = [-1,1] y=10^-3 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "# same results here ...\n",
    "# descent_history = grad(f, x=[-1, 1], y=0.01)\n",
    "# title = f\"x = [-1,1] y=10^-2 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "# draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "# descent_history = grad(f, x=[-1, 1], y=0.1)\n",
    "# title = f\"x = [-1,1] y=10^-1 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "# draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "# descent_history = grad(f, x=[0, 0], y=0.1)\n",
    "# title = \"x=[0,0] y=10^-1 Es un punto de silla de f, por lo que no convergio a ningun punto minimo\"\n",
    "# draw_function_3d_with_gradient(f, (-10, 10), descent_history, title=title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

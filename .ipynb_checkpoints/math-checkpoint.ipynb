{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02MIAR Actividad evaluada â€” ejercicio\n",
    "\n",
    "â—ï¸TODO: Agregar nombres\n",
    "\n",
    "Grupo 5 de Matematicas:\n",
    "\n",
    "- Julio Emanuel Suriano Bryk\n",
    "\n",
    "Para hacer:\n",
    "\n",
    "- Completar TODO\n",
    "- Cambiar comentarios al espaniol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup del proyecto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utils libs\n",
    "import copy\n",
    "import random\n",
    "from functools import reduce\n",
    "from timeit import timeit\n",
    "\n",
    "# graphical libs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# typehint libs\n",
    "from typing import Callable\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Avoid annoying warning for deprecations ...\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# make plots with visible on export\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers functions\n",
    "def get_square_matrix(n: int, n_range: tuple[int, int] = (-10, 10)) -> list[list]:\n",
    "    \"\"\"Genera una mÃ¡triz random de nxn tamaÃ±o\n",
    "\n",
    "    Args:\n",
    "        n (int): dimensiÃ³n de la mÃ¡triz\n",
    "        n_range (tuple[int, int], optional): rango de nÃ¹meros dentro de la mÃ¡triz\n",
    "\n",
    "    Returns:\n",
    "        list[list]: mÃ¡triz generada\n",
    "    \"\"\"\n",
    "    return [[random.randint(*n_range) for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "\n",
    "def matrix_to_str(matrix: list[list]) -> str:\n",
    "    \"\"\"Retorna una representaciÃ³n de una mÃ¡triz en string\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): mÃ¡triz para representar\n",
    "\n",
    "    Returns:\n",
    "        str: representaciÃ³n de la mÃ¡triz original\n",
    "    \"\"\"\n",
    "    digits = max(len(f\"{num:.2f}\") for row in matrix for num in row)\n",
    "    res = map(lambda row: \" \".join([f\"{n:{digits}.{2}f}\" for n in row]), matrix)\n",
    "    return \"\\n\".join(res)\n",
    "\n",
    "\n",
    "dimensions = [1, 2, 3, 4]\n",
    "\n",
    "for n in dimensions:\n",
    "    matrix = get_square_matrix(n)\n",
    "    print(f\"MÃ¡triz {n}x{n}: \")\n",
    "    print(matrix_to_str(matrix))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 (2 puntos). Desarrollo de Laplace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deducir de la definiciÃ³n 4 el determinante en dimensiÃ³n 0, 1 y 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeducciÃ³n del Determinante en Dimensiones 0, 1 y 2\n",
    "\n",
    "## DefiniciÃ³n 4 (Determinante)\n",
    "El determinante de una matriz, considerada como una lista de vectores, es la Ãºnica funciÃ³n lineal antisimÃ©trica de estos vectores tal que la matriz de la funciÃ³n identidad tenga determinante uno.\n",
    "\n",
    "### DimensiÃ³n 0\n",
    "\n",
    "En dimensiÃ³n 0, no hay vectores, por lo que la Ãºnica matriz posible es la matriz vacÃ­a. El determinante de la matriz vacÃ­a es 1 por convenciÃ³n.\n",
    "\n",
    "$$\n",
    "\\text{det}(\\text{matriz vacÃ­a}) = 1\n",
    "$$\n",
    "\n",
    "### DimensiÃ³n 1\n",
    "\n",
    "En dimensiÃ³n 1, tenemos una matriz $1 \\times 1$. Sea $A$ una matriz $1 \\times 1$ con un Ãºnico elemento $a_{11}$.\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix} a_{11} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Para que esta funciÃ³n sea lineal y antisimÃ©trica, debe cumplir con la propiedad de que el determinante de la matriz identidad es 1. La matriz identidad en dimensiÃ³n 1 es simplemente $1$.\n",
    "\n",
    "$$\n",
    "\\text{det}(1) = 1\n",
    "$$\n",
    "\n",
    "Para cualquier matriz $1 \\times 1$, el determinante es simplemente el valor del Ãºnico elemento:\n",
    "\n",
    "$$\n",
    "\\text{det}(A) = a_{11}\n",
    "$$\n",
    "\n",
    "### DimensiÃ³n 2\n",
    "\n",
    "En dimensiÃ³n 2, tenemos una matriz $2 \\times 2$. Sea $A$ una matriz $2 \\times 2$ con elementos $a_{ij}$.\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Para ser lineal y antisimÃ©trica, la funciÃ³n determinante debe cambiar de signo si intercambiamos dos vectores columna (o fila). AdemÃ¡s, el determinante de la matriz identidad debe ser 1. La matriz identidad en dimensiÃ³n 2 es:\n",
    "\n",
    "$$\n",
    "I = \\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{det}(I) = 1\n",
    "$$\n",
    "\n",
    "El determinante de una matriz $2 \\times 2$ se define como:\n",
    "\n",
    "$$\n",
    "\\text{det}(A) = a_{11}a_{22} - a_{21}a_{12}\n",
    "$$\n",
    "\n",
    "Esta fÃ³rmula asegura que:\n",
    "- Es lineal con respecto a cada fila y columna.\n",
    "- Es antisimÃ©trica: intercambiar dos filas o dos columnas cambia el signo del determinante.\n",
    "- La matriz identidad tiene determinante 1:\n",
    "\n",
    "$$\n",
    "\\text{det}\\left(\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\\right) = 1 \\cdot 1 - 0 \\cdot 0 = 1\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir de la definiciÃ³n 4, expresar el determinante de una matriz cuadrada recursivamente en funciÃ³n de determinantes la matrices cuadradas de dimensiÃ³n inferior.\n",
    "\n",
    "IndicaciÃ³n: para cada $ð‘› âˆˆ N$, distribuir (por linealidad en las columnas) sobre la descomposiciÃ³n\n",
    "\n",
    "$$\n",
    "\\det\\begin{pmatrix} ðœ† & w \\\\ v & A \\end{pmatrix} = \\det\\begin{pmatrix} ðœ† * 1 + 0 & w \\\\ ðœ† * 0 + v & A \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "de una matriz cuadrada de dimensiÃ³n $ð‘› + 1$, siendo $ð‘› âˆˆ N$ y\n",
    "\n",
    "- ðœ† un coeficiente real,\n",
    "- ð‘£ un vector de dimensiÃ³n ð‘› (una columna de ð‘› coeficientes reales),\n",
    "- ðœ” un covector de la misma dimensiÃ³n (una fila de ð‘› coeficientes),\n",
    "- ð´ una matriz cuadrada de la misma dimensiÃ³n (con ð‘›2 coeficientes),\n",
    "\n",
    "luego proceder del mismo modo\n",
    "\n",
    "- con los demÃ¡s coeficientes de esa primera columna,\n",
    "- con cada columna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExpresiÃ³n del Determinante Recursivamente\n",
    "\n",
    "### Desarrollo\n",
    "\n",
    "1. **ExpansiÃ³n por la primera columna**:\n",
    "   Sea $A$ una matriz cuadrada de dimensiÃ³n $n+1$. La matriz puede escribirse como:\n",
    "\n",
    "   $$\n",
    "   A = \\begin{pmatrix} \n",
    "   \\lambda & \\vec{\\omega} \\\\\n",
    "   \\vec{v} & B \n",
    "   \\end{pmatrix}\n",
    "   $$\n",
    "\n",
    "   donde:\n",
    "   - $\\lambda$ es el primer elemento de la primera columna,\n",
    "   - $\\vec{v}$ es el vector columna sin el primer elemento,\n",
    "   - $\\vec{\\omega}$ es el vector fila sin el primer elemento,\n",
    "   - $B$ es la submatriz de dimensiÃ³n $n$.\n",
    "\n",
    "2. **Determinante de una matriz $2 \\times 2$**:\n",
    "   Para una matriz $2 \\times 2$, tenemos:\n",
    "\n",
    "   $$\n",
    "   \\text{det}\\begin{pmatrix}\n",
    "   a_{11} & a_{12} \\\\\n",
    "   a_{21} & a_{22}\n",
    "   \\end{pmatrix} = a_{11}a_{22} - a_{12}a_{21}\n",
    "   $$\n",
    "\n",
    "3. **ExpansiÃ³n del determinante**:\n",
    "   La expansiÃ³n por la primera columna para una matriz $3 \\times 3$:\n",
    "\n",
    "   $$\n",
    "   \\text{det}\\begin{pmatrix}\n",
    "   a_{11} & a_{12} & a_{13} \\\\\n",
    "   a_{21} & a_{22} & a_{23} \\\\\n",
    "   a_{31} & a_{32} & a_{33}\n",
    "   \\end{pmatrix} = a_{11} \\text{det}\\begin{pmatrix}\n",
    "   a_{22} & a_{23} \\\\\n",
    "   a_{32} & a_{33}\n",
    "   \\end{pmatrix} - a_{12} \\text{det}\\begin{pmatrix}\n",
    "   a_{21} & a_{23} \\\\\n",
    "   a_{31} & a_{33}\n",
    "   \\end{pmatrix} + a_{13} \\text{det}\\begin{pmatrix}\n",
    "   a_{21} & a_{22} \\\\\n",
    "   a_{31} & a_{32}\n",
    "   \\end{pmatrix}\n",
    "   $$\n",
    "\n",
    "4. **GeneralizaciÃ³n**:\n",
    "   Para una matriz $(n+1) \\times (n+1)$:\n",
    "\n",
    "   $$\n",
    "   \\text{det}\\begin{pmatrix}\n",
    "   a_{11} & a_{12} & \\cdots & a_{1(n+1)} \\\\\n",
    "   a_{21} & a_{22} & \\cdots & a_{2(n+1)} \\\\\n",
    "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   a_{(n+1)1} & a_{(n+1)2} & \\cdots & a_{(n+1)(n+1)}\n",
    "   \\end{pmatrix} = \\sum_{j=1}^{n+1} (-1)^{1+j} a_{1j} \\text{det}(A_{1j})\n",
    "   $$\n",
    "\n",
    "   donde $A_{1j}$ es la matriz de dimensiÃ³n $n$ obtenida al eliminar la fila 1 y la columna $j$ de $A$.\n",
    "\n",
    "Entonces expresiÃ³n del determinante de una matriz cuadrada de dimensiÃ³n $n+1$ se puede obtener recursivamente a partir de los determinantes de matrices cuadradas de dimensiÃ³n $n$. Este proceso implica expandir el determinante por una fila o columna, utilizando la linealidad y la propiedad antisimÃ©trica del determinante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar en Python la definiciÃ³n asÃ­ obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_determinant(matrix: list[list]) -> float:\n",
    "    \"\"\"get determinant of a matrix using Laplace recursive method\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): squared matrix to obtain the determinant from\n",
    "\n",
    "    Raises:\n",
    "        Exception: in case the matrix is not squared\n",
    "\n",
    "    Returns:\n",
    "        float: value of the determinant\n",
    "    \"\"\"\n",
    "    if len(matrix) == 1:\n",
    "        return matrix[0]\n",
    "\n",
    "    if len(matrix) != len(matrix[0]):\n",
    "        raise Exception(\"Matriz no es cuadrada...\")\n",
    "\n",
    "    if len(matrix) == 2:\n",
    "        a, b = matrix[0]\n",
    "        c, d = matrix[1]\n",
    "        return a * d - b * c\n",
    "\n",
    "    res = 0\n",
    "    for i, n in enumerate(matrix[0]):\n",
    "        sub_matrix = [[el for j, el in enumerate(row) if j != i] for row in matrix[1:]]\n",
    "        res += n * (-1) ** i * laplace_determinant(sub_matrix)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "dimensions = [1, 2, 3, 4]\n",
    "\n",
    "for n in dimensions:\n",
    "    matrix = get_square_matrix(n)\n",
    "    print(f\"Matrix {n}x{n}: \")\n",
    "    print(matrix_to_str(matrix))\n",
    "    print(\"Determinante:\", laplace_determinant(matrix))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 (2 puntos). EliminaciÃ³n de Gaussâ€“Jordan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deducir de la definiciÃ³n 4 el efecto que tiene en el determinante de una matriz sumar a una de sus columnas una combinaciÃ³n lineal de las demÃ¡s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸ TODO: Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir de la definiciÃ³n 4, proponer una estrategia para triangularizar una matriz sin cambiar su determinante e implementar en Python una definiciÃ³n alternativa del determinante.\n",
    "\n",
    "IndicaciÃ³n: descomponer similarmente al ejercicio anterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—ï¸ TODO: Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar en Python la definiciÃ³n asÃ­ obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(initial_matrix: list[list]) -> tuple[list[list], float]:\n",
    "    \"\"\"perform the gaussian elimination method for a given matrix\n",
    "\n",
    "    Args:\n",
    "        initial_matrix (list[list]): matrix to apply gaussian elimination\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[list], float]: triangular matrix along with its determinant\n",
    "    \"\"\"\n",
    "    matrix = copy.deepcopy(initial_matrix)\n",
    "    n = len(matrix)\n",
    "\n",
    "    # keep track of row swaps to calculate final determinant\n",
    "    sign = 1\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        # find the proper row pivot to avoid zero division and rounded errors\n",
    "        max_row = max(range(i, n), key=lambda j: abs(matrix[j][i]))\n",
    "        if max_row != i:\n",
    "            matrix[i], matrix[max_row] = matrix[max_row], matrix[i]\n",
    "            sign *= -1\n",
    "\n",
    "        # apply rows operations in order to ensure triangularly of the matrix\n",
    "        for j in range(i + 1, n):\n",
    "            factor = matrix[j][i] / matrix[i][i]\n",
    "            for k in range(i, n):\n",
    "                matrix[j][k] -= matrix[i][k] * factor\n",
    "\n",
    "    # calculate determinant of a matrix using only the diagonal of it\n",
    "    diagonal_value = reduce(lambda acc, i: acc * matrix[i][i], range(n), 1)\n",
    "    determinant = diagonal_value * sign\n",
    "\n",
    "    return (matrix, determinant)\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(3)\n",
    "\n",
    "print(\"Matriz original:\")\n",
    "print(matrix_to_str(matrix))\n",
    "print(\"Determinante:\", laplace_determinant(matrix))\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "(triangular_matrix, triangular_determinant) = gaussian_elimination(matrix)\n",
    "print(\"Matriz triangular:\")\n",
    "print(matrix_to_str(triangular_matrix))\n",
    "print(\"Determinante:\", f\"{triangular_determinant:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 (2 puntos). ComparaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtener la complejidad computacional de cada una de estas dos implementaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complejidad computacional para el calculo del determinante:\n",
    "\n",
    "- Definicion con Laplace: $O(n!)$ por su propiedad recursiva\n",
    "- Definicion con Gauss: $O(n^3)$ son 3 `for` anidados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generar matrices aleatoriamente en dimensiÃ³n $ð‘› âˆˆ { 2, 3, Â· Â· Â· , 9, 10 }$ y comparar el tiempo de ejecuciÃ³n de cada una de estas dos implementaciones con la funciÃ³n `numpy.linalg.det` (la funciÃ³n determinante de la extensiÃ³n numÃ©rica de Python al Ã¡lgebra lineal).\n",
    "\n",
    "IndicaciÃ³n: se puede utilizar la funciÃ³n `numpy.random.rand` para generar los coeficientes aleatorios de sus matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "input_sizes = [np.random.rand(n, n).tolist() for n in range(2, 11)]\n",
    "\n",
    "for matrix in input_sizes:\n",
    "    n = len(matrix)\n",
    "    recur_time = timeit(lambda: laplace_determinant(matrix), number=1)\n",
    "    gauss_time = timeit(lambda: gaussian_elimination(matrix), number=1)\n",
    "    numpy_time = timeit(lambda: np.linalg.det(matrix), number=1)\n",
    "\n",
    "    data.extend(\n",
    "        [\n",
    "            [\"Recursive\", n, recur_time],\n",
    "            [\"Gauss\", n, gauss_time],\n",
    "            [\"Numpy\", n, numpy_time],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Method\", \"n\", \"Time\"])\n",
    "\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=\"n\",\n",
    "    y=\"Time\",\n",
    "    color=\"Method\",\n",
    "    markers=True,\n",
    "    title=\"Time to calculate matrix determinant\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 (4 puntos).\n",
    "\n",
    "Con el propÃ³sito de aproximar un mÃ­nimo local de una funciÃ³n real de varias variables reales, el mÃ©todo de descenso de gradiente consiste en iterar una marcha (positivamente) proporcional al (opuesto del) gradiente desde un valor inicial, con la intuiciÃ³n de â€˜seguir el aguaâ€™ hasta dar con el valle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementar en Python un algoritmo de descenso de gradiente (con un mÃ¡ximo de $m = 10**5$ iteraciones) a partir de los siguientes argumentos tomados en ese orden:\n",
    "\n",
    "- la funciÃ³n $f$ cuyo mÃ­nimo local se propone aproximar,\n",
    "- el valor inicial $x$ desde el que empieza la marcha,\n",
    "- la razÃ³n geomÃ©trica o coeficiente de proporcionalidad $y$,\n",
    "- el parÃ¡metro de tolerancia $z$ para finalizar cuando el gradiente de la funciÃ³n $f$ caiga dentro de esa tolerancia.\n",
    "\n",
    "IndicaciÃ³n: empezar por implementar el gradiente `grad(f)` de la funciÃ³n $f$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size\n",
    "\n",
    "\n",
    "def get_gradient_using_step(f: Callable, x: NDArray, epsilon=1e-8) -> NDArray:\n",
    "    \"\"\"calculate gradient for the function at a given point by using the method of\n",
    "\n",
    "    Args:\n",
    "        f (Callable): _description_\n",
    "        x (NDArray): _description_\n",
    "\n",
    "    Returns:\n",
    "        NDArray: _description_\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        x_plus = x.copy()\n",
    "        x_minus = x.copy()\n",
    "        x_plus[i] += epsilon\n",
    "        x_minus[i] -= epsilon\n",
    "        grad[i] = (f(*x_plus) - f(*x_minus)) / (2 * epsilon)\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def grad(\n",
    "    f: Callable,\n",
    "    x: NDArray,\n",
    "    y=0.01,\n",
    "    m=10**5,\n",
    "    z=1e-6,\n",
    ") -> list[NDArray]:\n",
    "    \"\"\"get minimum point of a function using method of gradient descent with step\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to find the minimum point\n",
    "        x (NDArray): start point to start looking for the minimum point\n",
    "        y (float, optional): learning rate to move the point on each iteration. Defaults to 0.01.\n",
    "        m (int, optional): numbers of max iterations to run. Defaults to 10**5.\n",
    "        z (float, optional): tolerance value to finish the algorithm in case we found point of convergence. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        list[NDArray]: history of the points inside the algorithm of gradient descent\n",
    "    \"\"\"\n",
    "    point = x\n",
    "    history = np.array([point])\n",
    "\n",
    "    for _ in range(m):\n",
    "        # get gradient from the derivate function\n",
    "        grad = get_gradient_using_step(f, point)\n",
    "\n",
    "        # Check for point convergence\n",
    "        if np.linalg.norm(grad) * 2 < z:\n",
    "            break\n",
    "\n",
    "        # get new point for the next iteration\n",
    "        point -= grad * y\n",
    "\n",
    "        # save it in history\n",
    "        history = np.concatenate((history, [point]), axis=0)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcular formalmente ${ ð‘¡ âˆˆ R. ð‘“ â€²(ð‘¡) = 0 }$ para $f(t) = 3t^4 + 4t^3 âˆ’ 12t^2 + 7$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  f'(t) = 12 t^3 + 12 t^2 - 24 t \\\\\n",
    "  f'(t) = 12 t (t^2 + t - 2)\n",
    "$$\n",
    "\n",
    "Para que $f'(t) = 0$, entonces los puntos criticos son:\n",
    "\n",
    "$$\n",
    "  t = -2\\\\\n",
    "  t = 0 \\\\\n",
    "  t = 1 \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Con una tolerancia $z = 10**-12$ y un valor inicial de $x = 3$ aplicar su algoritmo con razÃ³n $y = 10**-1, 10**-2, 10**-3$ luego hacer lo mismo con $x = 0$. Interpretar el resultado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—TODO: agregar interpretaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to draw functions\n",
    "\n",
    "plot_res = 100\n",
    "\n",
    "\n",
    "def prep_for_dataframe(data):\n",
    "    return {key: value.flatten() for key, value in data.items()}\n",
    "\n",
    "\n",
    "def draw_function_2d_with_gradient(\n",
    "    f: Callable,\n",
    "    graph_range: tuple[float, float],\n",
    "    descent_history: NDArray,\n",
    "    title: str,\n",
    "):\n",
    "    \"\"\"Crea un grÃ¡fico de una funciÃ³n en 2D con el descenso del gradiente\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "        title (str): title for the graph\n",
    "    \"\"\"\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    X = np.linspace(*graph_range, plot_res)\n",
    "    Y = f_vector(X)\n",
    "\n",
    "    data = {\"x\": descent_history, \"y\": f_vector(descent_history)}\n",
    "    descent_df = pd.DataFrame(prep_for_dataframe(data))\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter(x=X, y=Y, mode=\"lines\", name=\"Function\")])\n",
    "\n",
    "    try:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                **descent_df[[\"x\", \"y\"]].to_dict(\"list\"),\n",
    "                mode=\"markers\",\n",
    "                name=\"Gradiente\",\n",
    "            )\n",
    "        )\n",
    "    except OverflowError:\n",
    "        print(\"Cannot draw gradient history due to Overflow Error\")\n",
    "\n",
    "    start_point, end_point = descent_df.iloc[0], descent_df.iloc[-1]\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        annotations=(\n",
    "            [\n",
    "                dict(**start_point[[\"x\", \"y\"]], text=\"Comienzo\"),\n",
    "                dict(**end_point[[\"x\", \"y\"]], text=\"Fin\"),\n",
    "            ]\n",
    "            if len(descent_df) > 1\n",
    "            else [dict(**start_point[[\"x\", \"y\"]], text=\"Comienzo / Fin\")]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t: float) -> float:\n",
    "    return 3 * (t**4) + 4 * (t**3) - 12 * (t**2) + 7\n",
    "\n",
    "\n",
    "plot_range = (-3, 3)\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.001)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=f\"x = 3 y=10^-3 encontro punto minimo (local) en {descent_history[-1]}\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.01)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=f\"x = 3 y=10^-2 encontro punto minimo (global) en {descent_history[-1]}\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.1)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=\"x = 3 y=10^-1 no encontro un punto minimo valido por el alto valor de learning rate\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[0], y=0.001)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=\"x=0 y=10^-1 Es un punto de silla de f, por lo que no convergio a ningun punto minimo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repetir estos dos Ãºltimos apartados con $f: (s,t) â†’ s^2 + 3st + t^3 + 1$ y los valores iniciales $x = [-1,1], [0,0]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivadas parciales:\n",
    "\n",
    "$$\n",
    "  f'(s,t)_s = 2s + 3t \\\\\n",
    "  f'(s,t)_t = 3s + 3t ^2 \\\\\n",
    "$$\n",
    "\n",
    "Para que $f'(t) = 0$, entonces los puntos criticos son:\n",
    "\n",
    "$$\n",
    "  (s_1=0,t_1=0) \\\\\n",
    "  (s_2= 9/4, t_2= 3/2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â—TODO: agregar interpretaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting helper\n",
    "\n",
    "plot_res = 100\n",
    "\n",
    "\n",
    "def draw_function_3d_with_gradient(\n",
    "    f: Callable,\n",
    "    graph_range: tuple[float, float],\n",
    "    descent_history: NDArray,\n",
    "    title: str,\n",
    "):\n",
    "    \"\"\"Create plot using plotly to represent a gradient descent result of function\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "        title (str): title for the graph\n",
    "    \"\"\"\n",
    "    # Vectorize function in order to be possible to support numpy array operations\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    # Create a grid of x and y values\n",
    "    X, Y = np.meshgrid(\n",
    "        np.linspace(*graph_range, plot_res),\n",
    "        np.linspace(*graph_range, plot_res),\n",
    "    )\n",
    "    Z = f_vector(X, Y)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Surface(\n",
    "                z=Z,\n",
    "                x=X,\n",
    "                y=Y,\n",
    "                cmin=graph_range[0],\n",
    "                cmax=graph_range[1],\n",
    "                opacity=0.7,\n",
    "                name=\"Function\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # convert history to pandas df\n",
    "    data = {\n",
    "        \"x\": descent_history[:, 0],\n",
    "        \"y\": descent_history[:, 1],\n",
    "        \"z\": f_vector(descent_history[:, 0], descent_history[:, 1]),\n",
    "    }\n",
    "    descent_df = pd.DataFrame(prep_for_dataframe(data))\n",
    "\n",
    "    # add gradient line\n",
    "    fig.add_traces(\n",
    "        px.line_3d(\n",
    "            **descent_df.to_dict(), color_discrete_sequence=[\"white\"], title=\"Gradient\"\n",
    "        ).data\n",
    "    )\n",
    "\n",
    "    # mark start and end point of the gradient history\n",
    "    points_df = pd.concat([descent_df.iloc[[0]], descent_df.iloc[[-1]]])\n",
    "    fig.add_traces(\n",
    "        go.Scatter3d(\n",
    "            **points_df.to_dict(\"list\"),\n",
    "            mode=\"markers+text\",\n",
    "            text=([\"Comienzo\", \"Fin\"] if len(descent_df) > 1 else [\"Comienzo/Fin\"])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(zaxis=dict(range=graph_range)),\n",
    "        margin=dict(l=0, r=0, b=0),\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(s: float, t: float) -> float:\n",
    "    return s**2 + 3 * s * t + t**3 + 1\n",
    "\n",
    "\n",
    "descent_history = grad(f, x=[-1, 1], y=0.001)\n",
    "title = f\"x = [-1,1] y=10^-3 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "descent_history = grad(f, x=[-1, 1], y=0.01)\n",
    "title = f\"x = [-1,1] y=10^-2 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "descent_history = grad(f, x=[-1, 1], y=0.1)\n",
    "title = f\"x = [-1,1] y=10^-1 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "descent_history = grad(f, x=[0, 0], y=0.1)\n",
    "title = \"x=[0,0] y=10^-1 Es un punto de silla de f, por lo que no convergio a ningun punto minimo\"\n",
    "draw_function_3d_with_gradient(f, (-10, 10), descent_history, title=title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02MIAR Actividad evaluada — ejercicio\n",
    "\n",
    "❗️TODO: Agregar nombres\n",
    "\n",
    "Grupo 5 de Matematicas:\n",
    "\n",
    "- Julio Emanuel Suriano Bryk\n",
    "\n",
    "Para hacer:\n",
    "\n",
    "- Completar TODO\n",
    "- Cambiar comentarios al espaniol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup del proyecto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utils libs\n",
    "import copy\n",
    "import random\n",
    "from functools import reduce\n",
    "from timeit import timeit\n",
    "\n",
    "# graphical libs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# typehint libs\n",
    "from typing import Callable\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Avoid annoying warning for deprecations ...\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# make plots with visible on export\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers functions\n",
    "def get_square_matrix(n: int, n_range: tuple[int, int] = (-10, 10)) -> list[list]:\n",
    "    \"\"\"Genera una mátriz random de nxn tamaño\n",
    "\n",
    "    Args:\n",
    "        n (int): dimensión de la mátriz\n",
    "        n_range (tuple[int, int], optional): rango de nùmeros dentro de la mátriz\n",
    "\n",
    "    Returns:\n",
    "        list[list]: mátriz generada\n",
    "    \"\"\"\n",
    "    return [[random.randint(*n_range) for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "\n",
    "def matrix_to_str(matrix: list[list]) -> str:\n",
    "    \"\"\"Retorna una representación de una mátriz en string\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): mátriz para representar\n",
    "\n",
    "    Returns:\n",
    "        str: representación de la mátriz original\n",
    "    \"\"\"\n",
    "    digits = max(len(f\"{num:.2f}\") for row in matrix for num in row)\n",
    "    res = map(lambda row: \" \".join([f\"{n:{digits}.{2}f}\" for n in row]), matrix)\n",
    "    return \"\\n\".join(res)\n",
    "\n",
    "\n",
    "dimensions = [1, 2, 3, 4]\n",
    "\n",
    "for n in dimensions:\n",
    "    matrix = get_square_matrix(n)\n",
    "    print(f\"Mátriz {n}x{n}: \")\n",
    "    print(matrix_to_str(matrix))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 (2 puntos). Desarrollo de Laplace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deducir de la definición 4 el determinante en dimensión 0, 1 y 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deducción del Determinante en Dimensiones 0, 1 y 2\n",
    "\n",
    "## Definición 4 (Determinante)\n",
    "El determinante de una matriz, considerada como una lista de vectores, es la única función lineal antisimétrica de estos vectores tal que la matriz de la función identidad tenga determinante uno.\n",
    "\n",
    "### Dimensión 0\n",
    "\n",
    "En dimensión 0, no hay vectores, por lo que la única matriz posible es la matriz vacía. El determinante de la matriz vacía es 1 por convención.\n",
    "\n",
    "$$\n",
    "\\text{det}(\\text{matriz vacía}) = 1\n",
    "$$\n",
    "\n",
    "### Dimensión 1\n",
    "\n",
    "En dimensión 1, tenemos una matriz $1 \\times 1$. Sea $A$ una matriz $1 \\times 1$ con un único elemento $a_{11}$.\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix} a_{11} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Para que esta función sea lineal y antisimétrica, debe cumplir con la propiedad de que el determinante de la matriz identidad es 1. La matriz identidad en dimensión 1 es simplemente $1$.\n",
    "\n",
    "$$\n",
    "\\text{det}(1) = 1\n",
    "$$\n",
    "\n",
    "Para cualquier matriz $1 \\times 1$, el determinante es simplemente el valor del único elemento:\n",
    "\n",
    "$$\n",
    "\\text{det}(A) = a_{11}\n",
    "$$\n",
    "\n",
    "### Dimensión 2\n",
    "\n",
    "En dimensión 2, tenemos una matriz $2 \\times 2$. Sea $A$ una matriz $2 \\times 2$ con elementos $a_{ij}$.\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Para ser lineal y antisimétrica, la función determinante debe cambiar de signo si intercambiamos dos vectores columna (o fila). Además, el determinante de la matriz identidad debe ser 1. La matriz identidad en dimensión 2 es:\n",
    "\n",
    "$$\n",
    "I = \\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{det}(I) = 1\n",
    "$$\n",
    "\n",
    "El determinante de una matriz $2 \\times 2$ se define como:\n",
    "\n",
    "$$\n",
    "\\text{det}(A) = a_{11}a_{22} - a_{21}a_{12}\n",
    "$$\n",
    "\n",
    "Esta fórmula asegura que:\n",
    "- Es lineal con respecto a cada fila y columna.\n",
    "- Es antisimétrica: intercambiar dos filas o dos columnas cambia el signo del determinante.\n",
    "- La matriz identidad tiene determinante 1:\n",
    "\n",
    "$$\n",
    "\\text{det}\\left(\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\\right) = 1 \\cdot 1 - 0 \\cdot 0 = 1\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir de la definición 4, expresar el determinante de una matriz cuadrada recursivamente en función de determinantes la matrices cuadradas de dimensión inferior.\n",
    "\n",
    "Indicación: para cada $𝑛 ∈ N$, distribuir (por linealidad en las columnas) sobre la descomposición\n",
    "\n",
    "$$\n",
    "\\det\\begin{pmatrix} 𝜆 & w \\\\ v & A \\end{pmatrix} = \\det\\begin{pmatrix} 𝜆 * 1 + 0 & w \\\\ 𝜆 * 0 + v & A \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "de una matriz cuadrada de dimensión $𝑛 + 1$, siendo $𝑛 ∈ N$ y\n",
    "\n",
    "- 𝜆 un coeficiente real,\n",
    "- 𝑣 un vector de dimensión 𝑛 (una columna de 𝑛 coeficientes reales),\n",
    "- 𝜔 un covector de la misma dimensión (una fila de 𝑛 coeficientes),\n",
    "- 𝐴 una matriz cuadrada de la misma dimensión (con 𝑛2 coeficientes),\n",
    "\n",
    "luego proceder del mismo modo\n",
    "\n",
    "- con los demás coeficientes de esa primera columna,\n",
    "- con cada columna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expresión del Determinante Recursivamente\n",
    "\n",
    "### Desarrollo\n",
    "\n",
    "1. **Expansión por la primera columna**:\n",
    "   Sea $A$ una matriz cuadrada de dimensión $n+1$. La matriz puede escribirse como:\n",
    "\n",
    "   $$\n",
    "   A = \\begin{pmatrix} \n",
    "   \\lambda & \\vec{\\omega} \\\\\n",
    "   \\vec{v} & B \n",
    "   \\end{pmatrix}\n",
    "   $$\n",
    "\n",
    "   donde:\n",
    "   - $\\lambda$ es el primer elemento de la primera columna,\n",
    "   - $\\vec{v}$ es el vector columna sin el primer elemento,\n",
    "   - $\\vec{\\omega}$ es el vector fila sin el primer elemento,\n",
    "   - $B$ es la submatriz de dimensión $n$.\n",
    "\n",
    "2. **Determinante de una matriz $2 \\times 2$**:\n",
    "   Para una matriz $2 \\times 2$, tenemos:\n",
    "\n",
    "   $$\n",
    "   \\text{det}\\begin{pmatrix}\n",
    "   a_{11} & a_{12} \\\\\n",
    "   a_{21} & a_{22}\n",
    "   \\end{pmatrix} = a_{11}a_{22} - a_{12}a_{21}\n",
    "   $$\n",
    "\n",
    "3. **Expansión del determinante**:\n",
    "   La expansión por la primera columna para una matriz $3 \\times 3$:\n",
    "\n",
    "   $$\n",
    "   \\text{det}\\begin{pmatrix}\n",
    "   a_{11} & a_{12} & a_{13} \\\\\n",
    "   a_{21} & a_{22} & a_{23} \\\\\n",
    "   a_{31} & a_{32} & a_{33}\n",
    "   \\end{pmatrix} = a_{11} \\text{det}\\begin{pmatrix}\n",
    "   a_{22} & a_{23} \\\\\n",
    "   a_{32} & a_{33}\n",
    "   \\end{pmatrix} - a_{12} \\text{det}\\begin{pmatrix}\n",
    "   a_{21} & a_{23} \\\\\n",
    "   a_{31} & a_{33}\n",
    "   \\end{pmatrix} + a_{13} \\text{det}\\begin{pmatrix}\n",
    "   a_{21} & a_{22} \\\\\n",
    "   a_{31} & a_{32}\n",
    "   \\end{pmatrix}\n",
    "   $$\n",
    "\n",
    "4. **Generalización**:\n",
    "   Para una matriz $(n+1) \\times (n+1)$:\n",
    "\n",
    "   $$\n",
    "   \\text{det}\\begin{pmatrix}\n",
    "   a_{11} & a_{12} & \\cdots & a_{1(n+1)} \\\\\n",
    "   a_{21} & a_{22} & \\cdots & a_{2(n+1)} \\\\\n",
    "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   a_{(n+1)1} & a_{(n+1)2} & \\cdots & a_{(n+1)(n+1)}\n",
    "   \\end{pmatrix} = \\sum_{j=1}^{n+1} (-1)^{1+j} a_{1j} \\text{det}(A_{1j})\n",
    "   $$\n",
    "\n",
    "   donde $A_{1j}$ es la matriz de dimensión $n$ obtenida al eliminar la fila 1 y la columna $j$ de $A$.\n",
    "\n",
    "Entonces expresión del determinante de una matriz cuadrada de dimensión $n+1$ se puede obtener recursivamente a partir de los determinantes de matrices cuadradas de dimensión $n$. Este proceso implica expandir el determinante por una fila o columna, utilizando la linealidad y la propiedad antisimétrica del determinante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar en Python la definición así obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_determinant(matrix: list[list]) -> float:\n",
    "    \"\"\"get determinant of a matrix using Laplace recursive method\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): squared matrix to obtain the determinant from\n",
    "\n",
    "    Raises:\n",
    "        Exception: in case the matrix is not squared\n",
    "\n",
    "    Returns:\n",
    "        float: value of the determinant\n",
    "    \"\"\"\n",
    "    if len(matrix) == 1:\n",
    "        return matrix[0]\n",
    "\n",
    "    if len(matrix) != len(matrix[0]):\n",
    "        raise Exception(\"Matriz no es cuadrada...\")\n",
    "\n",
    "    if len(matrix) == 2:\n",
    "        a, b = matrix[0]\n",
    "        c, d = matrix[1]\n",
    "        return a * d - b * c\n",
    "\n",
    "    res = 0\n",
    "    for i, n in enumerate(matrix[0]):\n",
    "        sub_matrix = [[el for j, el in enumerate(row) if j != i] for row in matrix[1:]]\n",
    "        res += n * (-1) ** i * laplace_determinant(sub_matrix)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "dimensions = [1, 2, 3, 4]\n",
    "\n",
    "for n in dimensions:\n",
    "    matrix = get_square_matrix(n)\n",
    "    print(f\"Matrix {n}x{n}: \")\n",
    "    print(matrix_to_str(matrix))\n",
    "    print(\"Determinante:\", laplace_determinant(matrix))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 (2 puntos). Eliminación de Gauss–Jordan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deducir de la definición 4 el efecto que tiene en el determinante de una matriz sumar a una de sus columnas una combinación lineal de las demás.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ TODO: Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir de la definición 4, proponer una estrategia para triangularizar una matriz sin cambiar su determinante e implementar en Python una definición alternativa del determinante.\n",
    "\n",
    "Indicación: descomponer similarmente al ejercicio anterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ TODO: Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar en Python la definición así obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(initial_matrix: list[list]) -> tuple[list[list], float]:\n",
    "    \"\"\"perform the gaussian elimination method for a given matrix\n",
    "\n",
    "    Args:\n",
    "        initial_matrix (list[list]): matrix to apply gaussian elimination\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[list], float]: triangular matrix along with its determinant\n",
    "    \"\"\"\n",
    "    matrix = copy.deepcopy(initial_matrix)\n",
    "    n = len(matrix)\n",
    "\n",
    "    # keep track of row swaps to calculate final determinant\n",
    "    sign = 1\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        # find the proper row pivot to avoid zero division and rounded errors\n",
    "        max_row = max(range(i, n), key=lambda j: abs(matrix[j][i]))\n",
    "        if max_row != i:\n",
    "            matrix[i], matrix[max_row] = matrix[max_row], matrix[i]\n",
    "            sign *= -1\n",
    "\n",
    "        # apply rows operations in order to ensure triangularly of the matrix\n",
    "        for j in range(i + 1, n):\n",
    "            factor = matrix[j][i] / matrix[i][i]\n",
    "            for k in range(i, n):\n",
    "                matrix[j][k] -= matrix[i][k] * factor\n",
    "\n",
    "    # calculate determinant of a matrix using only the diagonal of it\n",
    "    diagonal_value = reduce(lambda acc, i: acc * matrix[i][i], range(n), 1)\n",
    "    determinant = diagonal_value * sign\n",
    "\n",
    "    return (matrix, determinant)\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(3)\n",
    "\n",
    "print(\"Matriz original:\")\n",
    "print(matrix_to_str(matrix))\n",
    "print(\"Determinante:\", laplace_determinant(matrix))\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "(triangular_matrix, triangular_determinant) = gaussian_elimination(matrix)\n",
    "print(\"Matriz triangular:\")\n",
    "print(matrix_to_str(triangular_matrix))\n",
    "print(\"Determinante:\", f\"{triangular_determinant:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 (2 puntos). Comparación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtener la complejidad computacional de cada una de estas dos implementaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complejidad computacional para el calculo del determinante:\n",
    "\n",
    "- Definicion con Laplace: $O(n!)$ por su propiedad recursiva\n",
    "- Definicion con Gauss: $O(n^3)$ son 3 `for` anidados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generar matrices aleatoriamente en dimensión $𝑛 ∈ { 2, 3, · · · , 9, 10 }$ y comparar el tiempo de ejecución de cada una de estas dos implementaciones con la función `numpy.linalg.det` (la función determinante de la extensión numérica de Python al álgebra lineal).\n",
    "\n",
    "Indicación: se puede utilizar la función `numpy.random.rand` para generar los coeficientes aleatorios de sus matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "input_sizes = [np.random.rand(n, n).tolist() for n in range(2, 11)]\n",
    "\n",
    "for matrix in input_sizes:\n",
    "    n = len(matrix)\n",
    "    recur_time = timeit(lambda: laplace_determinant(matrix), number=1)\n",
    "    gauss_time = timeit(lambda: gaussian_elimination(matrix), number=1)\n",
    "    numpy_time = timeit(lambda: np.linalg.det(matrix), number=1)\n",
    "\n",
    "    data.extend(\n",
    "        [\n",
    "            [\"Recursive\", n, recur_time],\n",
    "            [\"Gauss\", n, gauss_time],\n",
    "            [\"Numpy\", n, numpy_time],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Method\", \"n\", \"Time\"])\n",
    "\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=\"n\",\n",
    "    y=\"Time\",\n",
    "    color=\"Method\",\n",
    "    markers=True,\n",
    "    title=\"Time to calculate matrix determinant\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 (4 puntos).\n",
    "\n",
    "Con el propósito de aproximar un mínimo local de una función real de varias variables reales, el método de descenso de gradiente consiste en iterar una marcha (positivamente) proporcional al (opuesto del) gradiente desde un valor inicial, con la intuición de ‘seguir el agua’ hasta dar con el valle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementar en Python un algoritmo de descenso de gradiente (con un máximo de $m = 10**5$ iteraciones) a partir de los siguientes argumentos tomados en ese orden:\n",
    "\n",
    "- la función $f$ cuyo mínimo local se propone aproximar,\n",
    "- el valor inicial $x$ desde el que empieza la marcha,\n",
    "- la razón geométrica o coeficiente de proporcionalidad $y$,\n",
    "- el parámetro de tolerancia $z$ para finalizar cuando el gradiente de la función $f$ caiga dentro de esa tolerancia.\n",
    "\n",
    "Indicación: empezar por implementar el gradiente `grad(f)` de la función $f$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size\n",
    "\n",
    "\n",
    "def get_gradient_using_step(f: Callable, x: NDArray, epsilon=1e-8) -> NDArray:\n",
    "    \"\"\"calculate gradient for the function at a given point by using the method of\n",
    "\n",
    "    Args:\n",
    "        f (Callable): _description_\n",
    "        x (NDArray): _description_\n",
    "\n",
    "    Returns:\n",
    "        NDArray: _description_\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        x_plus = x.copy()\n",
    "        x_minus = x.copy()\n",
    "        x_plus[i] += epsilon\n",
    "        x_minus[i] -= epsilon\n",
    "        grad[i] = (f(*x_plus) - f(*x_minus)) / (2 * epsilon)\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def grad(\n",
    "    f: Callable,\n",
    "    x: NDArray,\n",
    "    y=0.01,\n",
    "    m=10**5,\n",
    "    z=1e-6,\n",
    ") -> list[NDArray]:\n",
    "    \"\"\"get minimum point of a function using method of gradient descent with step\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to find the minimum point\n",
    "        x (NDArray): start point to start looking for the minimum point\n",
    "        y (float, optional): learning rate to move the point on each iteration. Defaults to 0.01.\n",
    "        m (int, optional): numbers of max iterations to run. Defaults to 10**5.\n",
    "        z (float, optional): tolerance value to finish the algorithm in case we found point of convergence. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        list[NDArray]: history of the points inside the algorithm of gradient descent\n",
    "    \"\"\"\n",
    "    point = x\n",
    "    history = np.array([point])\n",
    "\n",
    "    for _ in range(m):\n",
    "        # get gradient from the derivate function\n",
    "        grad = get_gradient_using_step(f, point)\n",
    "\n",
    "        # Check for point convergence\n",
    "        if np.linalg.norm(grad) * 2 < z:\n",
    "            break\n",
    "\n",
    "        # get new point for the next iteration\n",
    "        point -= grad * y\n",
    "\n",
    "        # save it in history\n",
    "        history = np.concatenate((history, [point]), axis=0)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcular formalmente ${ 𝑡 ∈ R. 𝑓 ′(𝑡) = 0 }$ para $f(t) = 3t^4 + 4t^3 − 12t^2 + 7$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  f'(t) = 12 t^3 + 12 t^2 - 24 t \\\\\n",
    "  f'(t) = 12 t (t^2 + t - 2)\n",
    "$$\n",
    "\n",
    "Para que $f'(t) = 0$, entonces los puntos criticos son:\n",
    "\n",
    "$$\n",
    "  t = -2\\\\\n",
    "  t = 0 \\\\\n",
    "  t = 1 \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Con una tolerancia $z = 10**-12$ y un valor inicial de $x = 3$ aplicar su algoritmo con razón $y = 10**-1, 10**-2, 10**-3$ luego hacer lo mismo con $x = 0$. Interpretar el resultado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗TODO: agregar interpretaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to draw functions\n",
    "\n",
    "plot_res = 100\n",
    "\n",
    "\n",
    "def prep_for_dataframe(data):\n",
    "    return {key: value.flatten() for key, value in data.items()}\n",
    "\n",
    "\n",
    "def draw_function_2d_with_gradient(\n",
    "    f: Callable,\n",
    "    graph_range: tuple[float, float],\n",
    "    descent_history: NDArray,\n",
    "    title: str,\n",
    "):\n",
    "    \"\"\"Crea un gráfico de una función en 2D con el descenso del gradiente\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "        title (str): title for the graph\n",
    "    \"\"\"\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    X = np.linspace(*graph_range, plot_res)\n",
    "    Y = f_vector(X)\n",
    "\n",
    "    data = {\"x\": descent_history, \"y\": f_vector(descent_history)}\n",
    "    descent_df = pd.DataFrame(prep_for_dataframe(data))\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter(x=X, y=Y, mode=\"lines\", name=\"Function\")])\n",
    "\n",
    "    try:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                **descent_df[[\"x\", \"y\"]].to_dict(\"list\"),\n",
    "                mode=\"markers\",\n",
    "                name=\"Gradiente\",\n",
    "            )\n",
    "        )\n",
    "    except OverflowError:\n",
    "        print(\"Cannot draw gradient history due to Overflow Error\")\n",
    "\n",
    "    start_point, end_point = descent_df.iloc[0], descent_df.iloc[-1]\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        annotations=(\n",
    "            [\n",
    "                dict(**start_point[[\"x\", \"y\"]], text=\"Comienzo\"),\n",
    "                dict(**end_point[[\"x\", \"y\"]], text=\"Fin\"),\n",
    "            ]\n",
    "            if len(descent_df) > 1\n",
    "            else [dict(**start_point[[\"x\", \"y\"]], text=\"Comienzo / Fin\")]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t: float) -> float:\n",
    "    return 3 * (t**4) + 4 * (t**3) - 12 * (t**2) + 7\n",
    "\n",
    "\n",
    "plot_range = (-3, 3)\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.001)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=f\"x = 3 y=10^-3 encontro punto minimo (local) en {descent_history[-1]}\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.01)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=f\"x = 3 y=10^-2 encontro punto minimo (global) en {descent_history[-1]}\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[3], y=0.1)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=\"x = 3 y=10^-1 no encontro un punto minimo valido por el alto valor de learning rate\",\n",
    ")\n",
    "\n",
    "descent_history = grad(f, x=[0], y=0.001)\n",
    "draw_function_2d_with_gradient(\n",
    "    f,\n",
    "    plot_range,\n",
    "    descent_history,\n",
    "    title=\"x=0 y=10^-1 Es un punto de silla de f, por lo que no convergio a ningun punto minimo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repetir estos dos últimos apartados con $f: (s,t) → s^2 + 3st + t^3 + 1$ y los valores iniciales $x = [-1,1], [0,0]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivadas parciales:\n",
    "\n",
    "$$\n",
    "  f'(s,t)_s = 2s + 3t \\\\\n",
    "  f'(s,t)_t = 3s + 3t ^2 \\\\\n",
    "$$\n",
    "\n",
    "Para que $f'(t) = 0$, entonces los puntos criticos son:\n",
    "\n",
    "$$\n",
    "  (s_1=0,t_1=0) \\\\\n",
    "  (s_2= 9/4, t_2= 3/2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗TODO: agregar interpretaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting helper\n",
    "\n",
    "plot_res = 100\n",
    "\n",
    "\n",
    "def draw_function_3d_with_gradient(\n",
    "    f: Callable,\n",
    "    graph_range: tuple[float, float],\n",
    "    descent_history: NDArray,\n",
    "    title: str,\n",
    "):\n",
    "    \"\"\"Create plot using plotly to represent a gradient descent result of function\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "        title (str): title for the graph\n",
    "    \"\"\"\n",
    "    # Vectorize function in order to be possible to support numpy array operations\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    # Create a grid of x and y values\n",
    "    X, Y = np.meshgrid(\n",
    "        np.linspace(*graph_range, plot_res),\n",
    "        np.linspace(*graph_range, plot_res),\n",
    "    )\n",
    "    Z = f_vector(X, Y)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Surface(\n",
    "                z=Z,\n",
    "                x=X,\n",
    "                y=Y,\n",
    "                cmin=graph_range[0],\n",
    "                cmax=graph_range[1],\n",
    "                opacity=0.7,\n",
    "                name=\"Function\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # convert history to pandas df\n",
    "    data = {\n",
    "        \"x\": descent_history[:, 0],\n",
    "        \"y\": descent_history[:, 1],\n",
    "        \"z\": f_vector(descent_history[:, 0], descent_history[:, 1]),\n",
    "    }\n",
    "    descent_df = pd.DataFrame(prep_for_dataframe(data))\n",
    "\n",
    "    # add gradient line\n",
    "    fig.add_traces(\n",
    "        px.line_3d(\n",
    "            **descent_df.to_dict(), color_discrete_sequence=[\"white\"], title=\"Gradient\"\n",
    "        ).data\n",
    "    )\n",
    "\n",
    "    # mark start and end point of the gradient history\n",
    "    points_df = pd.concat([descent_df.iloc[[0]], descent_df.iloc[[-1]]])\n",
    "    fig.add_traces(\n",
    "        go.Scatter3d(\n",
    "            **points_df.to_dict(\"list\"),\n",
    "            mode=\"markers+text\",\n",
    "            text=([\"Comienzo\", \"Fin\"] if len(descent_df) > 1 else [\"Comienzo/Fin\"])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(zaxis=dict(range=graph_range)),\n",
    "        margin=dict(l=0, r=0, b=0),\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(s: float, t: float) -> float:\n",
    "    return s**2 + 3 * s * t + t**3 + 1\n",
    "\n",
    "\n",
    "descent_history = grad(f, x=[-1, 1], y=0.001)\n",
    "title = f\"x = [-1,1] y=10^-3 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "descent_history = grad(f, x=[-1, 1], y=0.01)\n",
    "title = f\"x = [-1,1] y=10^-2 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "descent_history = grad(f, x=[-1, 1], y=0.1)\n",
    "title = f\"x = [-1,1] y=10^-1 encontro punto minimo (local) en {descent_history[-1]}\"\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history, title=title)\n",
    "\n",
    "descent_history = grad(f, x=[0, 0], y=0.1)\n",
    "title = \"x=[0,0] y=10^-1 Es un punto de silla de f, por lo que no convergio a ningun punto minimo\"\n",
    "draw_function_3d_with_gradient(f, (-10, 10), descent_history, title=title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
